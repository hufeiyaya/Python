# -*- coding:utf-8 -*-
import requests
from requests.exceptions import RequestException
from bs4 import BeautifulSoup
from time import sleep
import pymongo


def get_one_page(url):
    try:
        headers = {
            "Accept": "*/*",
            "Accept-Encoding": "gzip, deflate, br",
            "Accept-Language": "zh-CN,zh;q=0.9",
            "Connection": "keep-alive",
            "Host": "sh.lianjia.com",
            "Upgrade - Insecure - Requests": "1",
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/75.0.3770.100 Safari/537.36"
        }
        response = requests.get("https://sh.lianjia.com/zufang/d0", headers=headers)
        if response.status_code == 200:
            return response.text
        else:
            return None
    except RequestException:
        return None


def parse_one_page(html, id):
    soup = BeautifulSoup(html, 'lxml')
    prefix = "https://sh.lianjia.com"
    for item in soup.select('.content__list--item'):
        houseInfo = item.find("img").get("alt")
        if "2室"  in houseInfo:
            houseUrl = prefix + item.find("a").get("href")
            housePrice = item.find(class_="content__list--item-price").get_text().split(" ")[0]
            houseTime = item.find(class_="content__list--item--time").get_text() 
            print("地址:  "+houseInfo + "   价格:"+housePrice+ "   发布时间:"+ houseTime + "   url:" +houseUrl)
            id += 1
            yield {
                '_id': id,
                'houseUrl': houseUrl,
                'houseInfo': houseInfo,
                'housePrice': housePrice,
                'houseTime': houseTime
            }, id
        

if __name__ == '__main__':
    client = pymongo.MongoClient('mongodb://localhost:27017')
    db_name = 'lianjia_zufang_shanghai'
    db = client[db_name]
    collection_set01 = db['set01']
    index = 0
    for page in range(70):
        sleep(1)
        url = 'https://sh.lianjia.com/zufang/minhang/d' + str(page)
        html = get_one_page(url)
        for item, index in parse_one_page(html, index):
            collection_set01.save(item)
